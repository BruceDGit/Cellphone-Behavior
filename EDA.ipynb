{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "train = pd.read_csv(data_path+'sensor_train.csv')\n",
    "test = pd.read_csv(data_path+'sensor_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment_id</th>\n",
       "      <th>time_point</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>acc_xg</th>\n",
       "      <th>acc_yg</th>\n",
       "      <th>acc_zg</th>\n",
       "      <th>behavior_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fragment_id  time_point  acc_x  acc_y  acc_z  acc_xg  acc_yg  acc_zg  \\\n",
       "0            0          27    0.3   -0.3    0.1     0.6     4.5     8.8   \n",
       "1            0         108    0.1   -0.0   -0.4     0.4     4.7     8.4   \n",
       "2            0         198    0.1    0.0    0.3     0.9     4.6     9.0   \n",
       "3            0         297    0.1   -0.1   -0.5     0.8     4.7     7.2   \n",
       "4            0         388    0.1    0.2    0.6     0.9     4.7     8.9   \n",
       "\n",
       "   behavior_id  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['abs_acc_x']=abs(train['acc_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment_id</th>\n",
       "      <th>time_point</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>acc_xg</th>\n",
       "      <th>acc_yg</th>\n",
       "      <th>acc_zg</th>\n",
       "      <th>behavior_id</th>\n",
       "      <th>abs_acc_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "      <td>425359.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3647.035972</td>\n",
       "      <td>2500.952026</td>\n",
       "      <td>0.009635</td>\n",
       "      <td>-0.063114</td>\n",
       "      <td>0.024548</td>\n",
       "      <td>0.965656</td>\n",
       "      <td>2.730190</td>\n",
       "      <td>7.825065</td>\n",
       "      <td>8.535035</td>\n",
       "      <td>0.307232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2103.253140</td>\n",
       "      <td>1442.307956</td>\n",
       "      <td>0.619285</td>\n",
       "      <td>0.537614</td>\n",
       "      <td>0.717009</td>\n",
       "      <td>3.295531</td>\n",
       "      <td>2.978134</td>\n",
       "      <td>2.653261</td>\n",
       "      <td>5.395264</td>\n",
       "      <td>0.537787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.700000</td>\n",
       "      <td>-14.700000</td>\n",
       "      <td>-12.600000</td>\n",
       "      <td>-19.800000</td>\n",
       "      <td>-16.900000</td>\n",
       "      <td>-8.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1252.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3646.000000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5466.000000</td>\n",
       "      <td>3749.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7291.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>34.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fragment_id     time_point          acc_x          acc_y  \\\n",
       "count  425359.000000  425359.000000  425359.000000  425359.000000   \n",
       "mean     3647.035972    2500.952026       0.009635      -0.063114   \n",
       "std      2103.253140    1442.307956       0.619285       0.537614   \n",
       "min         0.000000       0.000000     -14.700000     -14.700000   \n",
       "25%      1822.000000    1252.000000      -0.100000      -0.100000   \n",
       "50%      3646.000000    2501.000000       0.000000       0.000000   \n",
       "75%      5466.000000    3749.000000       0.100000       0.100000   \n",
       "max      7291.000000    4999.000000      34.500000      13.400000   \n",
       "\n",
       "               acc_z         acc_xg         acc_yg         acc_zg  \\\n",
       "count  425359.000000  425359.000000  425359.000000  425359.000000   \n",
       "mean        0.024548       0.965656       2.730190       7.825065   \n",
       "std         0.717009       3.295531       2.978134       2.653261   \n",
       "min       -12.600000     -19.800000     -16.900000      -8.900000   \n",
       "25%        -0.200000      -0.700000       0.400000       7.300000   \n",
       "50%         0.000000       0.200000       2.700000       8.700000   \n",
       "75%         0.200000       2.000000       4.900000       9.400000   \n",
       "max        28.200000      30.200000      14.400000      38.100000   \n",
       "\n",
       "         behavior_id      abs_acc_x  \n",
       "count  425359.000000  425359.000000  \n",
       "mean        8.535035       0.307232  \n",
       "std         5.395264       0.537787  \n",
       "min         0.000000       0.000000  \n",
       "25%         4.000000       0.000000  \n",
       "50%         8.000000       0.100000  \n",
       "75%        13.000000       0.400000  \n",
       "max        18.000000      34.500000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statics(data):\n",
    "    stats = []\n",
    "    for col in data.columns:\n",
    "        stats.append((col, data[col].nunique(), data[col].isnull().sum() * 100 / data.shape[0],\n",
    "                      data[col].value_counts(normalize=True, dropna=False).values[0] * 100, data[col].dtype))\n",
    "\n",
    "    stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique_values', 'Percentage_of_missing_values',\n",
    "                                            'Percentage_of_values_in_the_biggest category', 'type'])\n",
    "    stats_df.sort_values('Percentage_of_missing_values', ascending=False, inplace=True)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Unique_values</th>\n",
       "      <th>Percentage_of_missing_values</th>\n",
       "      <th>Percentage_of_values_in_the_biggest category</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fragment_id</td>\n",
       "      <td>7292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_point</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acc_x</td>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.568948</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc_y</td>\n",
       "      <td>159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.423393</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc_z</td>\n",
       "      <td>218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.457447</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc_xg</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.593905</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acc_yg</td>\n",
       "      <td>272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.087648</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acc_zg</td>\n",
       "      <td>284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.472457</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>behavior_id</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.260980</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Unique_values  Percentage_of_missing_values  \\\n",
       "0  fragment_id           7292                           0.0   \n",
       "1   time_point           5000                           0.0   \n",
       "2        acc_x            212                           0.0   \n",
       "3        acc_y            159                           0.0   \n",
       "4        acc_z            218                           0.0   \n",
       "5       acc_xg            300                           0.0   \n",
       "6       acc_yg            272                           0.0   \n",
       "7       acc_zg            284                           0.0   \n",
       "8  behavior_id             19                           0.0   \n",
       "\n",
       "   Percentage_of_values_in_the_biggest category     type  \n",
       "0                                      0.014341    int64  \n",
       "1                                      0.033148    int64  \n",
       "2                                     27.568948  float64  \n",
       "3                                     34.423393  float64  \n",
       "4                                     19.457447  float64  \n",
       "5                                      3.593905  float64  \n",
       "6                                      2.087648  float64  \n",
       "7                                      4.472457  float64  \n",
       "8                                     10.260980    int64  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats_df=statics(train)\n",
    "train_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                      | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_list ['time_point', 'acc_x', 'acc_y', 'acc_z', 'acc_xg', 'acc_yg', 'acc_zg']\n",
      "转化率特征....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  1.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "label = 'behavior_id'\n",
    "test['fragment_id'] += 10000\n",
    "\n",
    "data = pd.concat([train, test], sort=False)\n",
    "base_fea=['time_point','acc_x','acc_y','acc_z','acc_xg','acc_yg','acc_zg']\n",
    "for col in base_fea:\n",
    "    data['{}_rank'.format(col)] = data[col].rank()\n",
    "\n",
    "\n",
    "# print(\"加减乘除...\")\n",
    "# for a, b in tqdm(combinations(base_fea, 2)):\n",
    "#     data[str(a) + '+' + str(b)] = data[a].astype(float) + data[b].astype(float)\n",
    "#     data[str(a) + '-' + str(b)] = data[a].astype(float) - data[b].astype(float)\n",
    "#     data[str(a) + '*' + str(b)] = data[a].astype(float) * data[b].astype(float)\n",
    "# #     data[str(a) + '/' + str(b)] = data[a].astype(float) / (data[b].astype(float) + 1)\n",
    "    # df[str(a) + '/log' + str(b)] = df[a].astype(float) / np.log1p(df[b].astype(float))\n",
    "# # 类别特征计数\n",
    "# print(\"类别特征计数...\")\n",
    "# for i in tqdm(base_fea):\n",
    "#     data['{}_count'.format(i)] = data.groupby(['{}'.format(i)])['fragment_id'].transform('count')\n",
    "\n",
    "# # 类别特征nunqiue\n",
    "# print(\"类别特征nunqiue...\")\n",
    "# for i in tqdm(base_fea):\n",
    "#     for j in base_fea:\n",
    "#         if i != j:\n",
    "#             base_fea['nuni_{0}_{1}'.format(i, j)] = base_fea[i].map(base_fea.groupby(i)[j].nunique())\n",
    "\n",
    "def get_cvr_fea(df):\n",
    "    cat_list = ['time_point','acc_x','acc_y','acc_z','acc_xg','acc_yg','acc_zg']\n",
    "    print(\"cat_list\", cat_list)\n",
    "\n",
    "    # 类别特征五折转化率特征\n",
    "    print(\"转化率特征....\")\n",
    "    df['ID'] = df.index\n",
    "    df['fold'] = df['ID'] % 5\n",
    "    df.loc[df.behavior_id.isnull(), 'fold'] = 5\n",
    "    target_feat = []\n",
    "    for i in tqdm(cat_list):\n",
    "        target_feat.extend([i + '_mean_last_1'])\n",
    "        df[i + '_mean_last_1'] = None\n",
    "        for fold in range(6):\n",
    "            df.loc[df['fold'] == fold, i + '_mean_last_1'] = df[df['fold'] == fold][i].map(\n",
    "                df[(df['fold'] != fold) & (df['fold'] != 5)].groupby(i)['behavior_id'].mean()\n",
    "            )\n",
    "        df[i + '_mean_last_1'] = df[i + '_mean_last_1'].astype(float)\n",
    "\n",
    "    return df\n",
    "data = get_cvr_fea(data)\n",
    "\n",
    "data['acc'] = (data['acc_x'] ** 2 + data['acc_y'] ** 2 + data['acc_z'] ** 2) ** 0.5\n",
    "data['accg'] = (data['acc_xg'] ** 2 + data['acc_yg'] ** 2 + data['acc_zg'] ** 2) ** 0.5\n",
    "for j in tqdm(base_fea):\n",
    "    data['fragment_id_id_{}_mean'.format(j)] = data.groupby(['fragment_id'])[j].transform('mean')\n",
    "    data['fragment_id_id_{}_median'.format(j)] = data.groupby(['fragment_id'])[j].transform('median')\n",
    "    data['fragment_id_{}_max'.format(j)] = data.groupby(['fragment_id'])[j].transform('max')\n",
    "    data['fragment_id_id_{}_min'.format(j)] = data.groupby(['fragment_id'])[j].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_point',\n",
       " 'acc_x',\n",
       " 'acc_y',\n",
       " 'acc_z',\n",
       " 'acc_xg',\n",
       " 'acc_yg',\n",
       " 'acc_zg',\n",
       " 'time_point_rank',\n",
       " 'acc_x_rank',\n",
       " 'acc_y_rank',\n",
       " 'acc_z_rank',\n",
       " 'acc_xg_rank',\n",
       " 'acc_yg_rank',\n",
       " 'acc_zg_rank',\n",
       " 'ID',\n",
       " 'fold',\n",
       " 'time_point_mean_last_1',\n",
       " 'acc_x_mean_last_1',\n",
       " 'acc_y_mean_last_1',\n",
       " 'acc_z_mean_last_1',\n",
       " 'acc_xg_mean_last_1',\n",
       " 'acc_yg_mean_last_1',\n",
       " 'acc_zg_mean_last_1',\n",
       " 'acc',\n",
       " 'accg',\n",
       " 'fragment_id_id_time_point_mean',\n",
       " 'fragment_id_id_time_point_median',\n",
       " 'fragment_id_time_point_max',\n",
       " 'fragment_id_id_time_point_min',\n",
       " 'fragment_id_id_acc_x_mean',\n",
       " 'fragment_id_id_acc_x_median',\n",
       " 'fragment_id_acc_x_max',\n",
       " 'fragment_id_id_acc_x_min',\n",
       " 'fragment_id_id_acc_y_mean',\n",
       " 'fragment_id_id_acc_y_median',\n",
       " 'fragment_id_acc_y_max',\n",
       " 'fragment_id_id_acc_y_min',\n",
       " 'fragment_id_id_acc_z_mean',\n",
       " 'fragment_id_id_acc_z_median',\n",
       " 'fragment_id_acc_z_max',\n",
       " 'fragment_id_id_acc_z_min',\n",
       " 'fragment_id_id_acc_xg_mean',\n",
       " 'fragment_id_id_acc_xg_median',\n",
       " 'fragment_id_acc_xg_max',\n",
       " 'fragment_id_id_acc_xg_min',\n",
       " 'fragment_id_id_acc_yg_mean',\n",
       " 'fragment_id_id_acc_yg_median',\n",
       " 'fragment_id_acc_yg_max',\n",
       " 'fragment_id_id_acc_yg_min',\n",
       " 'fragment_id_id_acc_zg_mean',\n",
       " 'fragment_id_id_acc_zg_median',\n",
       " 'fragment_id_acc_zg_max',\n",
       " 'fragment_id_id_acc_zg_min']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_feat = []\n",
    "used_feat = [f for f in data.columns if f not in (['fragment_id', label] + drop_feat)]\n",
    "used_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855541, 55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data[used_feat] = min_max_scaler.fit_transform(data[used_feat])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = data[data[label].isna()==False].reset_index(drop=True)\n",
    "test = data[data[label].isna()==True].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425359, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430182, 55)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否存在NAN值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 425359 entries, 0 to 425358\n",
      "Data columns (total 55 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   fragment_id                       425359 non-null  int64  \n",
      " 1   time_point                        425359 non-null  float64\n",
      " 2   acc_x                             425359 non-null  float64\n",
      " 3   acc_y                             425359 non-null  float64\n",
      " 4   acc_z                             425359 non-null  float64\n",
      " 5   acc_xg                            425359 non-null  float64\n",
      " 6   acc_yg                            425359 non-null  float64\n",
      " 7   acc_zg                            425359 non-null  float64\n",
      " 8   behavior_id                       425359 non-null  float64\n",
      " 9   time_point_rank                   425359 non-null  float64\n",
      " 10  acc_x_rank                        425359 non-null  float64\n",
      " 11  acc_y_rank                        425359 non-null  float64\n",
      " 12  acc_z_rank                        425359 non-null  float64\n",
      " 13  acc_xg_rank                       425359 non-null  float64\n",
      " 14  acc_yg_rank                       425359 non-null  float64\n",
      " 15  acc_zg_rank                       425359 non-null  float64\n",
      " 16  ID                                425359 non-null  float64\n",
      " 17  fold                              425359 non-null  float64\n",
      " 18  time_point_mean_last_1            425359 non-null  float64\n",
      " 19  acc_x_mean_last_1                 425303 non-null  float64\n",
      " 20  acc_y_mean_last_1                 425326 non-null  float64\n",
      " 21  acc_z_mean_last_1                 425309 non-null  float64\n",
      " 22  acc_xg_mean_last_1                425327 non-null  float64\n",
      " 23  acc_yg_mean_last_1                425329 non-null  float64\n",
      " 24  acc_zg_mean_last_1                425317 non-null  float64\n",
      " 25  acc                               425359 non-null  float64\n",
      " 26  accg                              425359 non-null  float64\n",
      " 27  fragment_id_id_time_point_mean    425359 non-null  float64\n",
      " 28  fragment_id_id_time_point_median  425359 non-null  float64\n",
      " 29  fragment_id_time_point_max        425359 non-null  float64\n",
      " 30  fragment_id_id_time_point_min     425359 non-null  float64\n",
      " 31  fragment_id_id_acc_x_mean         425359 non-null  float64\n",
      " 32  fragment_id_id_acc_x_median       425359 non-null  float64\n",
      " 33  fragment_id_acc_x_max             425359 non-null  float64\n",
      " 34  fragment_id_id_acc_x_min          425359 non-null  float64\n",
      " 35  fragment_id_id_acc_y_mean         425359 non-null  float64\n",
      " 36  fragment_id_id_acc_y_median       425359 non-null  float64\n",
      " 37  fragment_id_acc_y_max             425359 non-null  float64\n",
      " 38  fragment_id_id_acc_y_min          425359 non-null  float64\n",
      " 39  fragment_id_id_acc_z_mean         425359 non-null  float64\n",
      " 40  fragment_id_id_acc_z_median       425359 non-null  float64\n",
      " 41  fragment_id_acc_z_max             425359 non-null  float64\n",
      " 42  fragment_id_id_acc_z_min          425359 non-null  float64\n",
      " 43  fragment_id_id_acc_xg_mean        425359 non-null  float64\n",
      " 44  fragment_id_id_acc_xg_median      425359 non-null  float64\n",
      " 45  fragment_id_acc_xg_max            425359 non-null  float64\n",
      " 46  fragment_id_id_acc_xg_min         425359 non-null  float64\n",
      " 47  fragment_id_id_acc_yg_mean        425359 non-null  float64\n",
      " 48  fragment_id_id_acc_yg_median      425359 non-null  float64\n",
      " 49  fragment_id_acc_yg_max            425359 non-null  float64\n",
      " 50  fragment_id_id_acc_yg_min         425359 non-null  float64\n",
      " 51  fragment_id_id_acc_zg_mean        425359 non-null  float64\n",
      " 52  fragment_id_id_acc_zg_median      425359 non-null  float64\n",
      " 53  fragment_id_acc_zg_max            425359 non-null  float64\n",
      " 54  fragment_id_id_acc_zg_min         425359 non-null  float64\n",
      "dtypes: float64(54), int64(1)\n",
      "memory usage: 178.5 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430182 entries, 0 to 430181\n",
      "Data columns (total 55 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   fragment_id                       430182 non-null  int64  \n",
      " 1   time_point                        430182 non-null  float64\n",
      " 2   acc_x                             430182 non-null  float64\n",
      " 3   acc_y                             430182 non-null  float64\n",
      " 4   acc_z                             430182 non-null  float64\n",
      " 5   acc_xg                            430182 non-null  float64\n",
      " 6   acc_yg                            430182 non-null  float64\n",
      " 7   acc_zg                            430182 non-null  float64\n",
      " 8   behavior_id                       0 non-null       float64\n",
      " 9   time_point_rank                   430182 non-null  float64\n",
      " 10  acc_x_rank                        430182 non-null  float64\n",
      " 11  acc_y_rank                        430182 non-null  float64\n",
      " 12  acc_z_rank                        430182 non-null  float64\n",
      " 13  acc_xg_rank                       430182 non-null  float64\n",
      " 14  acc_yg_rank                       430182 non-null  float64\n",
      " 15  acc_zg_rank                       430182 non-null  float64\n",
      " 16  ID                                430182 non-null  float64\n",
      " 17  fold                              430182 non-null  float64\n",
      " 18  time_point_mean_last_1            430182 non-null  float64\n",
      " 19  acc_x_mean_last_1                 430142 non-null  float64\n",
      " 20  acc_y_mean_last_1                 430157 non-null  float64\n",
      " 21  acc_z_mean_last_1                 430151 non-null  float64\n",
      " 22  acc_xg_mean_last_1                430154 non-null  float64\n",
      " 23  acc_yg_mean_last_1                430162 non-null  float64\n",
      " 24  acc_zg_mean_last_1                430085 non-null  float64\n",
      " 25  acc                               430182 non-null  float64\n",
      " 26  accg                              430182 non-null  float64\n",
      " 27  fragment_id_id_time_point_mean    430182 non-null  float64\n",
      " 28  fragment_id_id_time_point_median  430182 non-null  float64\n",
      " 29  fragment_id_time_point_max        430182 non-null  float64\n",
      " 30  fragment_id_id_time_point_min     430182 non-null  float64\n",
      " 31  fragment_id_id_acc_x_mean         430182 non-null  float64\n",
      " 32  fragment_id_id_acc_x_median       430182 non-null  float64\n",
      " 33  fragment_id_acc_x_max             430182 non-null  float64\n",
      " 34  fragment_id_id_acc_x_min          430182 non-null  float64\n",
      " 35  fragment_id_id_acc_y_mean         430182 non-null  float64\n",
      " 36  fragment_id_id_acc_y_median       430182 non-null  float64\n",
      " 37  fragment_id_acc_y_max             430182 non-null  float64\n",
      " 38  fragment_id_id_acc_y_min          430182 non-null  float64\n",
      " 39  fragment_id_id_acc_z_mean         430182 non-null  float64\n",
      " 40  fragment_id_id_acc_z_median       430182 non-null  float64\n",
      " 41  fragment_id_acc_z_max             430182 non-null  float64\n",
      " 42  fragment_id_id_acc_z_min          430182 non-null  float64\n",
      " 43  fragment_id_id_acc_xg_mean        430182 non-null  float64\n",
      " 44  fragment_id_id_acc_xg_median      430182 non-null  float64\n",
      " 45  fragment_id_acc_xg_max            430182 non-null  float64\n",
      " 46  fragment_id_id_acc_xg_min         430182 non-null  float64\n",
      " 47  fragment_id_id_acc_yg_mean        430182 non-null  float64\n",
      " 48  fragment_id_id_acc_yg_median      430182 non-null  float64\n",
      " 49  fragment_id_acc_yg_max            430182 non-null  float64\n",
      " 50  fragment_id_id_acc_yg_min         430182 non-null  float64\n",
      " 51  fragment_id_id_acc_zg_mean        430182 non-null  float64\n",
      " 52  fragment_id_id_acc_zg_median      430182 non-null  float64\n",
      " 53  fragment_id_acc_zg_max            430182 non-null  float64\n",
      " 54  fragment_id_id_acc_zg_min         430182 non-null  float64\n",
      "dtypes: float64(54), int64(1)\n",
      "memory usage: 180.5 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment_id</th>\n",
       "      <th>time_point</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>acc_xg</th>\n",
       "      <th>acc_yg</th>\n",
       "      <th>acc_zg</th>\n",
       "      <th>behavior_id</th>\n",
       "      <th>time_point_rank</th>\n",
       "      <th>...</th>\n",
       "      <th>fragment_id_acc_xg_max</th>\n",
       "      <th>fragment_id_id_acc_xg_min</th>\n",
       "      <th>fragment_id_id_acc_yg_mean</th>\n",
       "      <th>fragment_id_id_acc_yg_median</th>\n",
       "      <th>fragment_id_acc_yg_max</th>\n",
       "      <th>fragment_id_id_acc_yg_min</th>\n",
       "      <th>fragment_id_id_acc_zg_mean</th>\n",
       "      <th>fragment_id_id_acc_zg_median</th>\n",
       "      <th>fragment_id_acc_zg_max</th>\n",
       "      <th>fragment_id_id_acc_zg_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.199739</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.716332</td>\n",
       "      <td>0.285528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.722787</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.862863</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.19076</td>\n",
       "      <td>0.886463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.193211</td>\n",
       "      <td>0.436027</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>0.280313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.722787</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.862863</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.19076</td>\n",
       "      <td>0.886463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.039608</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.719198</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.722787</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.862863</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.19076</td>\n",
       "      <td>0.886463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.059412</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.191906</td>\n",
       "      <td>0.442761</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>0.264668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.722787</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.862863</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.19076</td>\n",
       "      <td>0.886463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.077616</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.332589</td>\n",
       "      <td>0.206266</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>0.286832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.722787</td>\n",
       "      <td>0.724324</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.824503</td>\n",
       "      <td>0.862863</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.19076</td>\n",
       "      <td>0.886463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fragment_id  time_point     acc_x     acc_y     acc_z    acc_xg    acc_yg  \\\n",
       "0            0    0.005401  0.324111  0.321429  0.199739  0.439394  0.716332   \n",
       "1            0    0.021604  0.320158  0.328125  0.193211  0.436027  0.722063   \n",
       "2            0    0.039608  0.320158  0.328125  0.202350  0.444444  0.719198   \n",
       "3            0    0.059412  0.320158  0.325893  0.191906  0.442761  0.722063   \n",
       "4            0    0.077616  0.320158  0.332589  0.206266  0.444444  0.722063   \n",
       "\n",
       "     acc_zg  behavior_id  time_point_rank  ...  fragment_id_acc_xg_max  \\\n",
       "0  0.285528          0.0         0.003919  ...                0.232941   \n",
       "1  0.280313          0.0         0.017101  ...                0.232941   \n",
       "2  0.288136          0.0         0.035000  ...                0.232941   \n",
       "3  0.264668          0.0         0.054702  ...                0.232941   \n",
       "4  0.286832          0.0         0.073102  ...                0.232941   \n",
       "\n",
       "   fragment_id_id_acc_xg_min  fragment_id_id_acc_yg_mean  \\\n",
       "0                   0.714689                    0.722787   \n",
       "1                   0.714689                    0.722787   \n",
       "2                   0.714689                    0.722787   \n",
       "3                   0.714689                    0.722787   \n",
       "4                   0.714689                    0.722787   \n",
       "\n",
       "   fragment_id_id_acc_yg_median  fragment_id_acc_yg_max  \\\n",
       "0                      0.724324                0.555556   \n",
       "1                      0.724324                0.555556   \n",
       "2                      0.724324                0.555556   \n",
       "3                      0.724324                0.555556   \n",
       "4                      0.724324                0.555556   \n",
       "\n",
       "   fragment_id_id_acc_yg_min  fragment_id_id_acc_zg_mean  \\\n",
       "0                   0.824503                    0.862863   \n",
       "1                   0.824503                    0.862863   \n",
       "2                   0.824503                    0.862863   \n",
       "3                   0.824503                    0.862863   \n",
       "4                   0.824503                    0.862863   \n",
       "\n",
       "   fragment_id_id_acc_zg_median  fragment_id_acc_zg_max  \\\n",
       "0                      0.895833                 0.19076   \n",
       "1                      0.895833                 0.19076   \n",
       "2                      0.895833                 0.19076   \n",
       "3                      0.895833                 0.19076   \n",
       "4                      0.895833                 0.19076   \n",
       "\n",
       "   fragment_id_id_acc_zg_min  \n",
       "0                   0.886463  \n",
       "1                   0.886463  \n",
       "2                   0.886463  \n",
       "3                   0.886463  \n",
       "4                   0.886463  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fragment_id统计\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7292, 7500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['fragment_id'].unique()),len(test['fragment_id'].unique()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取和理解数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences=list()\n",
    "base_fea=used_feat\n",
    "\n",
    "for index,group in train.groupby(by='fragment_id'):\n",
    "    train_sequences.append(group[base_fea].values)\n",
    "train_sequences[0]\n",
    "y_train=train.drop_duplicates(subset=['fragment_id']).reset_index(drop=True)['behavior_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7292.000000\n",
       "mean       58.332282\n",
       "std         1.668028\n",
       "min        50.000000\n",
       "25%        57.000000\n",
       "50%        58.000000\n",
       "75%        60.000000\n",
       "max        61.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sequences=[]\n",
    "for one_seq in train_sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "pd.Series(len_sequences).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7292, 61, 53)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding the sequence with the values in last row to max length\n",
    "to_pad=61\n",
    "train_new_seq=[]\n",
    "for one_seq in train_sequences:\n",
    "    len_one_seq=len(one_seq)\n",
    "    last_val=one_seq[-1]\n",
    "    n=to_pad-len_one_seq\n",
    "    to_concat=np.repeat(last_val,n).reshape(len(used_feat),n).transpose()\n",
    "    new_one_seq=np.concatenate([one_seq,to_concat])\n",
    "    train_new_seq.append(new_one_seq)\n",
    "\n",
    "train_final_seq=np.stack(train_new_seq)\n",
    "# final_seq.shape (314, 129, 4)\n",
    "train_final_seq.shape\n",
    "# 进行截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7292, 60, 53)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "seq_len=60\n",
    "train_final_seq=sequence.pad_sequences(train_final_seq,maxlen=seq_len,padding='post',\n",
    "                                dtype='float',truncating='post')\n",
    "train_final_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00540108, 0.32411067, 0.32142857, ..., 0.89583333,\n",
       "         0.19076006, 0.88646288],\n",
       "        [0.02160432, 0.3201581 , 0.328125  , ..., 0.89583333,\n",
       "         0.19076006, 0.88646288],\n",
       "        [0.03960792, 0.3201581 , 0.328125  , ..., 0.89583333,\n",
       "         0.19076006, 0.88646288],\n",
       "        ...,\n",
       "        [0.99039808, 0.32411067, 0.33035714, ..., 0.89583333,\n",
       "         0.19076006, 0.88646288],\n",
       "        [0.99039808, 0.32411067, 0.33035714, ..., 0.89583333,\n",
       "         0.19076006, 0.88646288],\n",
       "        [0.99039808, 0.32411067, 0.33035714, ..., 0.89583333,\n",
       "         0.19076006, 0.88646288]],\n",
       "\n",
       "       [[0.01160232, 0.31620553, 0.328125  , ..., 0.89583333,\n",
       "         0.19225037, 0.92576419],\n",
       "        [0.02920584, 0.3201581 , 0.328125  , ..., 0.89583333,\n",
       "         0.19225037, 0.92576419],\n",
       "        [0.04660932, 0.31818182, 0.33035714, ..., 0.89583333,\n",
       "         0.19225037, 0.92576419],\n",
       "        ...,\n",
       "        [0.99259852, 0.3201581 , 0.328125  , ..., 0.89583333,\n",
       "         0.19225037, 0.92576419],\n",
       "        [0.99259852, 0.3201581 , 0.328125  , ..., 0.89583333,\n",
       "         0.19225037, 0.92576419],\n",
       "        [0.99259852, 0.3201581 , 0.328125  , ..., 0.89583333,\n",
       "         0.19225037, 0.92576419]],\n",
       "\n",
       "       [[0.00340068, 0.31818182, 0.328125  , ..., 0.88888889,\n",
       "         0.19821162, 0.88646288],\n",
       "        [0.02060412, 0.3201581 , 0.328125  , ..., 0.88888889,\n",
       "         0.19821162, 0.88646288],\n",
       "        [0.03760752, 0.31818182, 0.32589286, ..., 0.88888889,\n",
       "         0.19821162, 0.88646288],\n",
       "        ...,\n",
       "        [0.99879976, 0.3201581 , 0.32589286, ..., 0.88888889,\n",
       "         0.19821162, 0.88646288],\n",
       "        [0.99879976, 0.3201581 , 0.32589286, ..., 0.88888889,\n",
       "         0.19821162, 0.88646288],\n",
       "        [0.99879976, 0.3201581 , 0.32589286, ..., 0.88888889,\n",
       "         0.19821162, 0.88646288]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.0070014 , 0.36561265, 0.34375   , ..., 0.33680556,\n",
       "         0.12071535, 0.41484716],\n",
       "        [0.02460492, 0.35375494, 0.26116071, ..., 0.33680556,\n",
       "         0.12071535, 0.41484716],\n",
       "        [0.04160832, 0.41501976, 0.36830357, ..., 0.33680556,\n",
       "         0.12071535, 0.41484716],\n",
       "        ...,\n",
       "        [0.98539708, 0.3201581 , 0.36607143, ..., 0.33680556,\n",
       "         0.12071535, 0.41484716],\n",
       "        [0.98539708, 0.3201581 , 0.36607143, ..., 0.33680556,\n",
       "         0.12071535, 0.41484716],\n",
       "        [0.98539708, 0.3201581 , 0.36607143, ..., 0.33680556,\n",
       "         0.12071535, 0.41484716]],\n",
       "\n",
       "       [[0.00940188, 0.36956522, 0.36830357, ..., 0.31944444,\n",
       "         0.10134128, 0.40611354],\n",
       "        [0.02640528, 0.3201581 , 0.32589286, ..., 0.31944444,\n",
       "         0.10134128, 0.40611354],\n",
       "        [0.04340868, 0.42885375, 0.35714286, ..., 0.31944444,\n",
       "         0.10134128, 0.40611354],\n",
       "        ...,\n",
       "        [0.98779756, 0.46837945, 0.39508929, ..., 0.31944444,\n",
       "         0.10134128, 0.40611354],\n",
       "        [0.98779756, 0.46837945, 0.39508929, ..., 0.31944444,\n",
       "         0.10134128, 0.40611354],\n",
       "        [0.98779756, 0.46837945, 0.39508929, ..., 0.31944444,\n",
       "         0.10134128, 0.40611354]],\n",
       "\n",
       "       [[0.00460092, 0.3458498 , 0.36830357, ..., 0.90625   ,\n",
       "         0.26229508, 0.53275109],\n",
       "        [0.02160432, 0.3201581 , 0.35714286, ..., 0.90625   ,\n",
       "         0.26229508, 0.53275109],\n",
       "        [0.03820764, 0.35968379, 0.34151786, ..., 0.90625   ,\n",
       "         0.26229508, 0.53275109],\n",
       "        ...,\n",
       "        [0.98359672, 0.34189723, 0.29017857, ..., 0.90625   ,\n",
       "         0.26229508, 0.53275109],\n",
       "        [0.98359672, 0.34189723, 0.29017857, ..., 0.90625   ,\n",
       "         0.26229508, 0.53275109],\n",
       "        [0.98359672, 0.34189723, 0.29017857, ..., 0.90625   ,\n",
       "         0.26229508, 0.53275109]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 60, 53)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences=list()\n",
    "base_fea=used_feat\n",
    "\n",
    "for index,group in test.groupby(by='fragment_id'):\n",
    "    test_sequences.append(group[base_fea].values)\n",
    "\n",
    "# padding the sequence with the values in last row to max length\n",
    "to_pad=61\n",
    "test_new_seq=[]\n",
    "for one_seq in test_sequences:\n",
    "    len_one_seq=len(one_seq)\n",
    "    last_val=one_seq[-1]\n",
    "    n=to_pad-len_one_seq\n",
    "    to_concat=np.repeat(last_val,n).reshape(len(used_feat),n).transpose()\n",
    "    new_one_seq=np.concatenate([one_seq,to_concat])\n",
    "    test_new_seq.append(new_one_seq)\n",
    "\n",
    "test_final_seq=np.stack(test_new_seq)\n",
    "# final_seq.shape (314, 129, 4)\n",
    "test_final_seq.shape\n",
    "\n",
    "\n",
    "# 进行截断\n",
    "from keras.preprocessing import sequence\n",
    "seq_len=60\n",
    "test_final_seq=sequence.pad_sequences(test_final_seq,maxlen=seq_len,padding='post',\n",
    "                                dtype='float',truncating='post')\n",
    "test_final_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打乱数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X,y=shuffle(train_final_seq,y_train,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 19)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 60, 53)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               317440    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19)                4883      \n",
      "=================================================================\n",
      "Total params: 322,323\n",
      "Trainable params: 322,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer=Input(shape=(seq_len,len(used_feat)),name=\"input_layer\")\n",
    "lstm_layer=LSTM(256)(input_layer)\n",
    "# bp=BatchNormalization()(lstm_layer)\n",
    "# dense=Dense(64)(bp)\n",
    "pred=Dense(19,activation='softmax')(lstm_layer)\n",
    "model=Model(input_layer,pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.001)\n",
    "checkpoint=ModelCheckpoint('data/best_model.pkl',monitor='val_accuracy',save_best_only=True,verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "205/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.02603, saving model to data/best_model.pkl\n",
      "INFO:tensorflow:Assets written to: data/best_model.pkl\\assets\n",
      "206/206 [==============================] - 4s 21ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 2/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00002: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 3/100\n",
      "205/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0337\n",
      "Epoch 00003: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 4/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0334\n",
      "Epoch 00004: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 5/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00005: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 6/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00006: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 7/100\n",
      "206/206 [==============================] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00007: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 8/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00008: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 9/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00009: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 10/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0331\n",
      "Epoch 00010: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 11/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0333- ETA: 0s - loss: 14.4467 - accuracy: - ETA: 0s - loss: 14.4467 - accurac\n",
      "Epoch 00011: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 12/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0341\n",
      "Epoch 00012: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 13/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0331\n",
      "Epoch 00013: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 14/100\n",
      "201/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00014: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 15/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0333\n",
      "Epoch 00015: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 16/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0334\n",
      "Epoch 00016: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 17/100\n",
      "201/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00017: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 18/100\n",
      "199/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0333\n",
      "Epoch 00018: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 19/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0334\n",
      "Epoch 00019: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 20/100\n",
      "204/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0337\n",
      "Epoch 00020: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 21/100\n",
      "199/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0330\n",
      "Epoch 00021: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 22/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0334\n",
      "Epoch 00022: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 23/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00023: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 24/100\n",
      "205/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338- ETA: 0s - loss: 14.4467\n",
      "Epoch 00024: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 25/100\n",
      "199/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0336\n",
      "Epoch 00025: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 26/100\n",
      "205/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00026: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 27/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0335\n",
      "Epoch 00027: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 28/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00028: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00029: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 30/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00030: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 31/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00031: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 32/100\n",
      "204/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0337\n",
      "Epoch 00032: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 33/100\n",
      "203/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0337\n",
      "Epoch 00033: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 34/100\n",
      "206/206 [==============================] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00034: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 35/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00035: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 36/100\n",
      "206/206 [==============================] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00036: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 37/100\n",
      "205/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00037: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 38/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0337\n",
      "Epoch 00038: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 39/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00039: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 40/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00040: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 41/100\n",
      "201/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00041: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 42/100\n",
      "204/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00042: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 43/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0331\n",
      "Epoch 00043: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 44/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00044: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 45/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0344e+0 - ETA: 1s - loss: 14.4466 \n",
      "Epoch 00045: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 46/100\n",
      "201/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00046: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 47/100\n",
      "199/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0333\n",
      "Epoch 00047: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 48/100\n",
      "206/206 [==============================] - ETA: 0s - loss: 14.4466 - accuracy: 0.0338\n",
      "Epoch 00048: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 49/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00049: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 50/100\n",
      "199/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0344\n",
      "Epoch 00050: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 51/100\n",
      "199/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0336\n",
      "Epoch 00051: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 52/100\n",
      "201/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0340\n",
      "Epoch 00052: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 53/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00053: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 54/100\n",
      "202/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0342\n",
      "Epoch 00054: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 6ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 55/100\n",
      "201/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00055: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 56/100\n",
      "198/206 [===========================>..] - ETA: 0s - loss: 14.4466 - accuracy: 0.0339\n",
      "Epoch 00056: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 57/100\n",
      "200/206 [============================>.] - ETA: 0s - loss: 14.4466 - accuracy: 0.0333\n",
      "Epoch 00057: val_accuracy did not improve from 0.02603\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 14.4466 - accuracy: 0.0338 - val_loss: 14.4467 - val_accuracy: 0.0260\n",
      "Epoch 58/100\n",
      "143/206 [===================>..........] - ETA: 0s - loss: 14.4467 - accuracy: 0.0326"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint,early_stop],\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载以前保存的权重\n",
    "model=tf.keras.models.load_model('./data/best_model.pkl')\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_preds=model.predict(test_final_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label=np.argmax(test_preds,axis=1)\n",
    "pd.Series(label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(data_path+'提交结果示例.csv')\n",
    "sub['behavior_id'] = label\n",
    "sub.to_csv('result/lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
